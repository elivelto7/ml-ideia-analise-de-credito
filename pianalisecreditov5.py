# -*- coding: utf-8 -*-
"""PIAnaliseCreditoV5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mqvkUcNi3E__Df84qEDXCeBqvTPYDh61

## IdeiA Análise de Crédito - Machine Learning - PI DSM 6 2024/1

**PI DSM6-2024/1**

**Grupo Armazém de Ideias**

**Marcelo Luiz Siqueira Reis**

**João Paulo Cardoso Rodrigues**

**Elivelto Silva**

**IdeiA Análise de Crédito para aprovação de cartão de crédito**

**Introdução**

Uma das principais características do ser humano é ser gregário, mas nenhum grupo é autossuficiente sendo necessário o intercâmbio de objetos. E dessas trocas surgiu o comércio.

Visando otimizar as vendas o crédito passou a ser um instrumento importantíssimo para a economia.

Muito antes do surgimento do sistema econômico capitalista, já haviam as "bancas" no final da idade média que desempenhavam o papel das instituições financeiras.

Entretanto, a concessão de crédito não é algo simples ou pode ser concedida arbitrariamente, a prática já demonstrou que critérios devem ser observados na análise de crédito.

O setor financeiro estabeleceu pontuações durante a análise de crédito para prever a probabilidade de inadimplência de cartão de crédito e orientar a emissão deles. Essas pontuações dependem dos dados pessoais e informações históricas dos solicitantes, de modo a quantificar objetivamente o risco.

Neste contexto é o presente projeto para criar um modelo classificador de machine learning para ajudar os bancos a decidir quem deve obter um cartão de crédito.

##Carregando os dados
"""

from google.colab import drive
drive.mount('/content/drive')

# importando bibliotecas

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
import joblib
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.options.display.float_format = '{:.2f}'.format
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler , LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score , classification_report, f1_score, precision_score, recall_score

"""Trabalhando com o conjunto de dados application_record.csv"""

#importando o arquivo
df_application = pd.read_csv('/content/application_record.csv', sep=',')
df_application.head()

# conhecendo o conjunto de dados (application_record)

print(f'O conjunto de dados application_record.csv possui {df_application.shape[0]} linhas','\n')

print(f'O conjunto de dados application_recordo.csv possui {df_application.shape[1]} colunas')

#verificando datatypes
df_application.dtypes

"""Conforme se observa o conjunto de dados application_record.csv possui 8 (oito) colunas/atributos object datatype (categóricos) e 10 (dez) colunas/atributos numeric datatype (numéricos).

Agora vamos verificar o conjunto de dados credit_record.csv
"""

#importando o arquivo
df_credit = pd.read_csv('/content/credit_record.csv', sep=',')
df_credit.head()

# conhecendo o conjunto de dados (credit_record)

print(f'O conjunto de dados credit_record.csv possui {df_credit.shape[0]} linhas','\n')

print(f'O conjunto de dados credit_record.csv possui {df_credit.shape[1]} colunas')

#verificando datatypes
df_credit.dtypes

"""Conforme se observa o conjunto de dados credit_record.csv possui 1 (uma) coluna/atributo object datatype (categórico) e 2 (duas) colunas/atributos numeric datatype (numéricos).

**Merging (mesclando) os dois conjuntos de dados com base na coluna comum ID**

Nós mesclamos os dois dataframes com base na coluna ID presente em ambos os conjuntos de dados.
Além disso, verifica-se que o conjunto de dados credit_record.csv tem mais registros de clientes do que o conjunto de dados application_record.csv, então se faz necessário garantr que o novo dataframe (df_merge) contenha apenas as linhas que têm o mesmo número de ID
Para esse propósito, usamos o parâmetro inner na função pd.merge
"""

# Merging (mesclando) os dois conjuntos de dados com base no ID

df_merge = pd.merge(df_application, df_credit, on='ID' , how='inner')

"""**Visualizando o conjunto de dados mesclado (merged)**"""

df_merge.head()

# conhecendo o novo conjunto de dados mesclado (application_record.csv + credit_record.csv)

print(f'O novo conjunto de dados mesclado (df_merge) possui {df_merge.shape[0]} linhas','\n')

print(f'O novo conjunto de dados mesclado (df_merge) possui {df_merge.shape[1]} colunas')

"""'''**Entendo a base**

ID: Número do cliente

CODE_GENDER: Sexo

FLAG_OWN_CAR: Possui carro

FLAG_OWN_REALTY: Possui imóvel

CNT_CHILDREN: Número de filhos

AMT_INCOME_TOTAL: Renda anual

NAME_INCOME_TYPE: Tipo de renda

NAME_EDUCATION_TYPE: Grau de escolaridade

NAME_FAMILY_STATUS: Estado civil

NAME_HOUSING_TYPE: Tipo de Moradia

DAYS_BIRTH: Aniversário em dias. Atenção: Contagem regressiva a partir do dia atual (0), -1 significa ontem

DAYS_EMPLOYED: Data de início do emprego. Atenção: Contagem regressiva a partir do dia atual (0). Se positivo, significa que a pessoa está desempregada no momento.

FLAG_MOBIL: Possui telefone celular

FLAG_WORK_PHONE: Possui telefone comercial

FLAG_PHONE: Possui telefone fixo

FLAG_EMAIL: Possui e-mail

OCCUPATION_TYPE: Tipo de ocupação

CNT_FAM_MEMBERS: Tamanho da família

MONTHS_BALANCE: Mês do registro dos dados. Atenção: O mês dos dados extraídos é o ponto de partida, para trás, 0 é o mês atual, -1 é o mês anterior e assim por diante

STATUS: Status. Atenção: 0: 1-29 dias em atraso 1: 30-59 dias em atraso 2: 60-89 dias em atraso 3: 90-119 dias em atraso 4: 120-149 dias em atraso 5: Dívidas vencidas ou incobráveis, baixas por mais de 150 dias C: quitado naquele mês X: Nenhum empréstimo no mês

**Verificando valores ausentes**
"""

# verificando valores nulos
df_merge.isna().sum()

# plotando heatmap para verificar valores nulos

# definindo o tamanho da figura
plt.figure(figsize=(10, 6))

# plotando heatmap de valores ausentes
sns.heatmap(df_merge.isna(), cbar=False , yticklabels=False, cmap='viridis')

# definindo o título
plt.title('Heatmap para valores ausentes')
plt.xticks(rotation=50)
plt.show()

# verificação da porcentagem de valores ausentes na coluna/atributo `OCCUPATION_TYPE`

df_merge['OCCUPATION_TYPE'].isna().sum() / df_merge.shape[0] * 100

"""Analisando o novo conjunto de dados mesclado verifica-se que há apenas uma coluna*atributo que tem valores nulos.

Esta coluna/atributo é OCCUPATION_TYPE e tem 240048 valores ausentes o que corresponde a uma porcentagem de 30,86% de valores ausentes.

Ante o exposto, a opção é remover a coluna/atributo OCCUPATION_TYPE porque ela tem uma alta porcentagem de valores ausentes e como cada pessoa tem seu registro exclusivo, não se pode imputar valores para os ausentes.
"""

# excluindo a coluna/atributo OCCUPATION_TYPE
df_merge.drop('OCCUPATION_TYPE', axis=1, inplace=True)

# verificando o resultado
df_merge.columns

# verificando a contagem de valores exclusivos em cada coluna/atributo
df_merge.nunique()

df_merge.info()

"""**Atenção**

Embora o novo conjunto de dados mesclado tenha 777715 linhas, constata-se que a coluna/atributo ID possui apenas 36457 valores únicos, o que demonstra ser um indicativo de que pode haver valores duplicados no conjunto de dados.

**Tratamento de dados redundantes**
"""

# verificando valores duplicados
df_merge.duplicated().sum()

df_merge[df_merge['ID'].duplicated()].head(20)

df_merge[df_merge['ID'].duplicated()].tail(20)

"""Apesar do conjunto de dados possuir 36457 clientes identificados pela coluna/atributo ID, verifica-se que não há duplicatas, tendo em vista que os dados são coletaados com base em diferentes meses, consoante coluna/atributo MONTHS_BALANCE

**Renomeando as colunas**

Para uma melhor visualização se faz necessário renomear as colunas para palavras em português
"""

# verificando as colunas
df_merge.columns

# renomeando as colunas para ter sentido em português

df_merge.rename(columns={
    'CODE_GENDER': 'genero',
    'FLAG_OWN_CAR': 'carro_proprio',
    'FLAG_OWN_REALTY': 'casa_propria',
    'CNT_CHILDREN': 'filhos',
    'AMT_INCOME_TOTAL': 'renda',
    'NAME_INCOME_TYPE': 'tipo_de_renda',
    'NAME_EDUCATION_TYPE': 'grau_de_escolaridade',
    'NAME_FAMILY_STATUS': 'estado_civil',
    'NAME_HOUSING_TYPE': 'tipo_de_moradia',
    'FLAG_MOBIL': 'celular',
    'FLAG_WORK_PHONE': 'telefone_trabalho',
    'FLAG_PHONE': 'telefone',
    'FLAG_EMAIL': 'email',
    'CNT_FAM_MEMBERS': 'membros_da_familia',
    'MONTHS_BALANCE': 'saldo_meses',
    'STATUS' : 'status',
    'DAYS_BIRTH' : 'idade_em_dias',
    'DAYS_EMPLOYED' : 'dias_empregado'

} , inplace=True)

df_merge.columns

# verificando colunas object dtype

df_merge.select_dtypes(include='object').columns

# verificando valores únicos em algumas colunas

col = ['genero', 'carro_proprio', 'casa_propria']

for i in col:
    print(f'{df_merge[i].value_counts()}')

# mapeando os valores em algumas colunas


# mapeando entradas únicas de gênero
df_merge['genero'] = df_merge['genero'].map({'F':'feminino', 'M': 'masculino'})

# mapeando entradas únicas de carro_proprio
df_merge['carro_proprio'] = df_merge['carro_proprio'].map({'N': 'nao', 'Y': 'sim'})

# mapeando entradas únicas de casa_propria
df_merge['casa_propria'] = df_merge['casa_propria'].map({'N': 'nao', 'Y': 'sim'})

# mapeando entradas únicas de tipo de renda
df_merge['tipo_de_renda'] = df_merge['tipo_de_renda'].map({'Working':'trabalhando',
                                                           'Commercial associate': 'representante comercial',
                                                           'Pensioner': 'aposentado',
                                                           'State servant': 'funcionario publico',
                                                           'Student': 'estudante'})

# mapeando entradas únicas de grau de escolaridade
df_merge['grau_de_escolaridade'] = df_merge['grau_de_escolaridade'].map({'Secondary / secondary special':'ensino medio / tecnico',
                                                           'Higher education': 'ensino superior',
                                                           'Incomplete higher': 'superior incompleto',
                                                           'Lower secondary': 'ensino medio incompleto',
                                                           'Academic degree': 'tecnologo'})

# mapeando entradas únicas de estado civil
df_merge['estado_civil'] = df_merge['estado_civil'].map({'Married': 'casado',
                                                         'Civil marriage': 'casado',
                                                         'Single / not married': 'solteiro',
                                                         'Separated': 'divorciado',
                                                         'Widow': 'viuvo'})

# mapeando entradas únicas de tipo de moradia
df_merge['tipo_de_moradia'] = df_merge['tipo_de_moradia'].map({'House / apartment':'imovel proprio',
                                                           'With parents': 'mora com os pais',
                                                           'Municipal apartment': 'imovel financiado',
                                                           'Rented apartment': 'imovel alugado',
                                                           'Office apartment': 'imovel comercial',
                                                           'Co-op apartment': 'imovel compartilhado'})

# Criando faixa etaria para utilizarmos no modelo preditivo
bins = [-36500, -21900, -18250, -14600, -10950, -7665, -1]
labels = ['Acima de 60 Anos', 'De 51 ate 60 Anos', 'De 41 ate 50 Anos', 'De 31 ate 40 Anos', 'De 22 ate 30 Anos', 'Ate 21 Anos'] # Adjusted labels to match the new bin order
df_merge['faixa_etaria'] = pd.cut(df_merge['idade_em_dias'], bins=bins, labels=labels)
df_merge.groupby(['faixa_etaria']).size()

# Criando renda anual para utilizarmos no modelo preditivo
bins = [-100, 500000, 650000, 800000, 950000, 1100000, 1250000, 1400000, 5000000]
labels = ['Ate 500k', 'De 500k ate 650k', 'De 650k ate 800k', 'De 800k ate 950k', 'De 950k ate 1100k',
          'De 1100k ate 1250k', 'De 1250k ate 1400k', 'De 1400k ate 5000k']
df_merge['renda_anual'] = pd.cut(df_merge['renda'], bins=bins, labels=labels)
df_merge.groupby(['renda_anual']).size()

# Criando tempo emprego para utilizarmos no modelo preditivo
bins = [-20000, -14600, -10950, -7300, -3650, -1825, -1, 500000]
labels = ['Acima de 40 Anos', 'De 31 ate 40 Anos', 'De 21 ate 30 Anos', 'De 11 ate 20 Anos', 'De 6 ate 10 Anos', 'Ate 5 Anos', 'Desempregado']
df_merge['tempo_emprego'] = pd.cut(df_merge['dias_empregado'], bins=bins, labels=labels)
df_merge.groupby(['tempo_emprego']).size()

# Criando tempo registro dos dados para utilizarmos no modelo preditivo
bins = [-100, -48, -36, -24, -12, -1, 100000]
labels = ['Acima de 48 Meses', 'De 36 ate 47 Meses', 'De 24 ate 35 Meses', 'De 13 ate 23 Meses', 'De 1 ate 12 Meses', 'Nenhum mes']
df_merge['tempo_registro_dados'] = pd.cut(df_merge['saldo_meses'], bins=bins, labels=labels)
df_merge.groupby(['tempo_registro_dados']).size()

# verificando valores únicos na coluna status

df_merge['status'].value_counts()

# mapeando os valores na coluna status e armazenando o resultado na nova coluna status_do_emprestimo

df_merge['status_do_emprestimo'] = df_merge['status'].map({'0': 'Reprovado',
                                                           '1': 'Reprovado',
                                                           '2': 'Reprovado',
                                                           '3': 'Reprovado',
                                                           '4': 'Reprovado',
                                                           '5': 'Reprovado',
                                                           'C': 'Aprovado',
                                                           'X' : 'Aprovado'})

df_merge.status_do_emprestimo.value_counts()

# confirmando o resultado

df_merge.columns.values

# Criação de novo conjunto de dados
columns = ['ID', 'genero', 'carro_proprio', 'casa_propria', 'filhos', 'tipo_de_renda', 'grau_de_escolaridade',
           'estado_civil', 'tipo_de_moradia', 'celular', 'telefone_trabalho', 'telefone', 'email', 'membros_da_familia',
           'faixa_etaria', 'renda_anual', 'tempo_emprego', 'tempo_registro_dados', 'status_do_emprestimo']

df_juntado = pd.DataFrame(df_merge, columns=columns)

df_juntado.to_csv('application_credit_record_v5.csv', index=False)

"""Prosseguindo com a análise exploratória de dados, o principal objetivo é analisar os diferentes atributos dos clientes, a distribuição dos dados, o relacionamento entre os atributos e em especial obter uma visão geral do relacionamento entre os atributos e a classe (variável de destino) status_do_emprestimo.

**Verificando a distribuição de 'genero', 'carro_proprio', 'casa_propria'**
"""

# Definir a lista de nomes de colunas
columns = ['genero', 'carro_proprio', 'casa_propria']

# Criar subplots para cada coluna
plt.figure(figsize=(16 , 9))  # Ajustar o tamanho da figura conforme necessário

for i in range(len(columns)):
    plt.subplot(1, 3, i+1)
    plt.title(columns[i])  # Usar o nome da coluna como título

    # Plotar gráfico pizza
    counts = df_merge[columns[i]].value_counts()
    plt.pie(counts, labels=counts.index, autopct='%1.1f%%'  )

    # Adicionar legendas com valores exclusivos
    plt.legend(counts.index)
plt.show()

# criando lista de colunas específicas
col = ['genero', 'carro_proprio', 'casa_propria', 'tipo_de_renda',]

# definindo o tamnanho da figura
plt.figure(figsize=(15, 6))

# plotando o countplot usando loop for
for i in range(len(col)):
    # definindo o subplot
    plt.subplot(2, 2, i+1)
    # adicionando título
    plt.title(col[i])
    # plotando o countplot
    sns.countplot(data=df_merge, x=df_merge[col[i]])
    # girando os rótulos do eixo x
    plt.xticks(rotation=45)
# ajuste de layout
plt.tight_layout()
plt.show()

"""Conforme se observa há mais clientes mulheres do que homens, o número de clientes que não têm carro é maior que aqueles que têm, enquanto que, os clientes com casa própria são a maioria."""

# verificando a contagem de status_do_emprestimo

df_merge['status_do_emprestimo'].value_counts()

"""**Obtendo insights do 'status_do_emprestimo' X 'genero'**"""

# verificando a relação entre o status do empréstimo e o gênero

# definindo o tamanho da figura
plt.figure(figsize=(15, 5))

# plotando o countplot (gráfico de contagem)
sns.countplot(data=df_merge, x=df_merge['status_do_emprestimo'], hue=df_merge['genero'])

# definindo o título
plt.title('status do empréstimo X genero')
# girando os rótulos do eixo x
plt.xticks(rotation=25)
plt.show()

# obtendo insights do status do empréstimo X gênero
df_merge.columns # obtendo os nomes exatos das colunas

# verificando a contagem de valores do tipo de renda

df_merge['tipo_de_renda'].value_counts()

# verificando a relação entre o tipo de renda e o gênero

count = df_merge['tipo_de_renda'].value_counts()

plt.figure(figsize=(15, 6))

# Plotando o countplot (gráfico de contagem) para cada valor único de 'tipo_de_renda'
for i in range(len(count)):
    plt.subplot(2, 3, i+1)
    plt.title(count.index[i])  # Use o valor único do 'tipo_de_renda' como valor único
    sns.countplot(data=df_merge[df_merge['tipo_de_renda'] == count.index[i]], x='genero')

plt.tight_layout()  # Ajuste o layout para evitar sobreposição
plt.show()

# verificando a relação entre status do empréstimo e tipo de renda

# definindo o tamanho da figura
plt.figure(figsize=(15, 5))

# plotando o countplot (gráfico de contagem)
sns.countplot(data=df_merge, x=df_merge['status_do_emprestimo'], hue=df_merge['tipo_de_renda'])

# definindo o título
plt.title('Gráfico de contagem de status_do_emprestimo X tipo_de_renda')
plt.xticks(rotation=25)
plt.show()

# obtendo insights de gênero X tipo de renda e status do empréstimo com contagens de valores menores que 1000
count = df_merge.groupby('genero')[['tipo_de_renda', 'status_do_emprestimo']].value_counts()

count[count<1000].unstack()

# verificando a relação entre gênero X tipo de renda e status do empréstimo
count = df_merge.groupby('genero')[['tipo_de_renda', 'status_do_emprestimo' ]].value_counts()

# plotando o gráfico de barh para contagem de valores (genero X tipo de renda e status do emprestimo) menor que 1.000
count[count<1000].unstack().plot(kind='bar' , figsize=(15, 5) , legend=True )
# definindo o título
plt.title('Relação entre gênero X status do empréstimo e tipo de renda (contagem de valores < 1.000)')
# girando os rótulos do eixo x
plt.xticks(rotation=25)
plt.show()

# gráfico de área da relação entre gênero X tipo de renda e status do empréstimo com contagens de valores menores que 1.000
# verificando a relação entre gênero X tipo de renda e status do empréstimo
count = df_merge.groupby('genero')[['status_do_emprestimo','tipo_de_renda']].value_counts()
# plotando o gráfico de área para (gênero X tipo de renda e status do empréstimo) contagem de valores menores que 1.000
count[count<1000].unstack().plot(kind='area' , figsize=(15, 9))
# definindo o título
plt.title('Relação entre gênero X tipo de renda e status do empréstimo (contagem de valor < 1.000)')
# girando os rótulos do eixo x
plt.xticks(rotation=25)
plt.show()

# verificando a contagem de valores da educação
df_merge.grau_de_escolaridade.value_counts()

# verificando a relação entre gênero e educação
df_merge.groupby('genero')[['grau_de_escolaridade']].value_counts()

# plotando o countplot para grau de escolaridade X gênero
df_merge.groupby('genero')[['grau_de_escolaridade']].value_counts().unstack().plot(kind='bar', figsize=(15, 5) , stacked=True)

# girando os rótulos do eixo x
plt.xticks(rotation=360)

# definindo o título
plt.title('Relação entre gênero e grau de escolaridade')
plt.show()

# verificando a relação entre status do empréstimo e grau de escolaridade usando a função groupby
df_merge.groupby('grau_de_escolaridade')[['status_do_emprestimo']].value_counts().unstack().plot(kind='bar', figsize=(15, 5) , stacked= True)
# definindo o título
plt.title('Relação entre status do empréstimo e grau de escolaridade')
# girando os rótulos do eixo x
plt.xticks(rotation=25)
plt.show()

# verificando a relação entre status do empréstimo e grau de escolaridade
count = df_merge.groupby('grau_de_escolaridade')[['status_do_emprestimo']].value_counts()

# plotando o gráfico de barh para grau de escolaridade X status do empréstimo que têm valores menores que 500
count[count<=500].unstack().plot(kind='barh' , figsize=(15, 6))
# definindo o título
plt.title('Relacionamento entre status do empréstimo e grau de escolaridade (valor contagem < 500)')
# girando os rótulos do eixo x
plt.xticks(rotation=25)
plt.show()

# verificando as entradas unique da coluna tipo de moradia

df_merge['tipo_de_moradia'].unique()

# verificando contagens de valores da coluna tipo de moradia
df_merge['tipo_de_moradia'].value_counts()

# verificando a relação entre status do empréstimo e tipo de moradia

# definindo o tamanho da figura
plt.figure(figsize=(15, 5))

# plotando o countplot
sns.countplot(data=df_merge, x=df_merge['status_do_emprestimo'], hue=df_merge['tipo_de_moradia'])

plt.xticks(rotation=25)
plt.title('Relação entre status do empréstimo e tipo de moradia')

plt.show()

# verificando a relação entre status do empréstimo e tipo de moradia

# agrupar por tipo de moradia e status do empréstimo para obter suas contagens
count = df_merge.groupby(['tipo_de_moradia', 'status_do_emprestimo']).size()

# Obter contagens de valor onde status do empréstimo é divida ruim
emprestimo_ruim= count[count.index.get_level_values('status_do_emprestimo') == 'Reprovado']
emprestimo_ruim

# verificando os nomes das colunas
df_merge.columns

# verificando a contagem dos valores da coluna membros_da_familia
df_merge.membros_da_familia.value_counts()

# verificando o relacionamento entre status do empréstimo e membros da família
df_merge.groupby('membros_da_familia')[['status_do_emprestimo']].value_counts().unstack()

df_merge.select_dtypes(exclude='object').columns # verificando o nome das colunas com numeric datatype

# verificando a contagem de valores de filhos
df_merge.filhos.value_counts()

# verificando a relação entre status do empréstimo e filhos

df_merge.groupby('filhos')[['status_do_emprestimo']].value_counts().unstack()

df_merge.isnull().sum()

# filtrar dataframe onde dias empregado > 0
df_merge.tempo_emprego.value_counts()

"""No conjunto de dados há 127972 pessoas desempregadas.

##Pré-processamento
"""

# informar o nome das colunas
df_merge.columns

# plotando o gráfico de dispersão de colunas numéricas
# verificando a relação entre status do empréstimo e renda
col = ['filhos', 'renda_anual', 'faixa_etaria',  'membros_da_familia' , 'tempo_emprego']

# definindo o tamanho da figura
plt.figure(figsize=(15, 6))

# plotando o countplot usando o loop for
for i in range(len(col)):
    plt.subplot(3, 2, i+1)
    plt.title(col[i])  # Usar o nome da coluna como título
    sns.scatterplot(data=df_merge, y=col[i], x='ID')
plt.title('Gráfico de dispersão (scatterplot) de ID X colunas numéricas')
plt.tight_layout()  # Ajuste o layout para evitar sobreposição
plt.show()

df_merge.columns

# plotando o boxplot de colunas nunéricas
# verificando a relação entre status do empréstimo e renda

# filtrando a lista de colunas específicas
col = ['filhos', 'renda_anual', 'faixa_etaria',  'membros_da_familia' ]

# definindo o tamanho da figura
plt.figure(figsize=(15, 6))

# plotando o countplot usando o loop for
for i in range(len(col)):
    plt.subplot(3, 2, i+1)
    plt.title(col[i])  # Use o nome da coluna como título
    sns.boxplot(data=df_merge, y=col[i])

plt.tight_layout()  # Ajuste o layout para evitar sobreposição
plt.show()

"""Verifica-se que os outliers estão presentes em duas colunas: filhos, membros_da_familia. Tanto o gráfico de dispersão quanto o gráfico de caixa estão mostrando outliers nas colunas supra mencionadas.

**Remoção de outliers**
"""

# removendo outliers

# filtrando a lista de colunas específicas
col = ['filhos', 'membros_da_familia']

# loop para remover outliers
for i in range(len(col)):
    # calculando o primeiro e o terceiro quartil
    q1 = df_merge[col[i]].quantile(0.25)
    q3 = df_merge[col[i]].quantile(0.75)
    # calculando o intervalo interquartil
    iqr = q3 - q1
    # calculando os limites inferior e superior
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    # substituindo os outliers pela mediana
    df_merge[col[i]] = np.where((df_merge[col[i]] >= upper_bound) | (df_merge[col[i]] <= lower_bound), df_merge[col[i]].median() , df_merge[col[i]])

# plotando o bocplot novamente para confirmar os resultados
col = ['filhos', 'membros_da_familia']

plt.figure(figsize=(15, 6))

for i in range(len(col)):
    plt.subplot(2, 2, i+1)
    plt.title(col[i])  # Use o nome da coluna como título
    sns.boxplot(data=df_merge, y=col[i])

plt.tight_layout()  # Ajuste o layout para evitar sobreposição
plt.show()

df_merge.isnull().sum()

df_merge.columns

df_merge.select_dtypes(exclude='object').columns

df_dados = df_juntado

df_dados.isnull().sum()

df_dados.genero.value_counts()

df_dados.info(verbose=True)

"""**Padronização (Standartization)**"""

# filtrando a lista de colunas específicas
col = ['filhos', 'membros_da_familia']

# chamando o escalonador padrão
sc = StandardScaler()
# loop for para escalonar as colunas específicas
for i in col:
    df_dados[i] = sc.fit_transform(df_dados[[i]])

"""**Adequação do modelo: Random Forest Classifier**"""

# verificando a distribuição de status do empréstimo
df_merge.status_do_emprestimo.value_counts().plot(kind='barh', figsize=(15, 5))
# definindo o título
plt.title('Distribuição de classe dentro do status do empréstimo')
plt.show()

"""O status_do_emprestimo é a classe (variável alvo). Verifica-se que a classe alvo é altamente desbalanceada. O que significa que não se pode usar regressão logística nos dados. Ante o exposto, o algoritmo Random Forest Classifier é o melhor modelo a ser utilizado."""

df_dados.head()

"""**Label Encoding**

A transformação de dados categóricos em númericos é parte essencial no pré-processamento, no presente projeto, analisando o conjunto de dados, a técnica escolhida é o Label Encoding.
"""

# retornando os nomes das colunas
df_dados.columns

df_dados.info()

# filtrando a lista de colunas específicas que necessitam aplicar técnica de codificar (encode)
col = ['genero', 'carro_proprio', 'casa_propria', 'tipo_de_renda','grau_de_escolaridade', 'estado_civil',
       'tipo_de_moradia', 'faixa_etaria', 'renda_anual', 'tempo_emprego', 'tempo_registro_dados']

# chamando o label encoder (codificador de rótulo)
le = LabelEncoder()

# loop for para codificar as colunas específicas
for i in col:
    df_dados[i] =le.fit_transform(df_dados[i])

df_dados.head()

"""**Verificando a Multicolinearidade**

Multicolinearidade ocorre quando duas ou mais variáveis preditoras em um modelo estão altamente correlacionadas entre si. Isso significa que uma variável pode ser prevista com uma precisão razoável a partir de outras variáveis no modelo. A multicolinearidade pode causar problemas no modelo de regressão, pois dificulta a determinação da influência individual de cada variável preditora na variável resposta. Isso pode resultar em coeficientes instáveis e imprecisos, bem como intervalos de confiança amplos.
A técnica **Variance Inflation Factor - VIF (Fator de Inflação da Variância)** é uma ferramenta usada para detectar e quantificar a multicolinearidade. O VIF para uma variável preditora específica é uma medida da inflação da variância de seu coeficiente de regressão devido à sua correlação com outras variáveis preditoras no modelo. Um VIF de 1 indica a ausência de multicolinearidade, enquanto valores maiores que 1 indicam um grau crescente de multicolinearidade. Geralmente, um VIF de 10 ou maior é considerado indicativo de um problema significativo de multicolinearidade.
"""

# Remova as colunas 'status_do_emprestimo' e 'status' de col
col = df_dados.drop(['status_do_emprestimo'], axis=1) # Assuma que col é nossa variável independente

# Calcule a variance inflation factor - VIF (fator de inflação de variância)

# Crie um dataframe para armazenar o VIF
factor  = pd.DataFrame(columns=["VIF", "Features"] )
# Para cada coluna, calcule o VIF
factor["Features"] = col.columns
factor["VIF"] = [variance_inflation_factor(col.values, i) for i in range(col.shape[1])]

# Exiba os resultados
factor

"""**Treino e teste**"""

#Dividindo o conjunto de dados em recursos e rótulos
X = df_dados.drop(['status_do_emprestimo' , 'filhos' , 'membros_da_familia', 'celular'], axis = 1)
y = df_dados['status_do_emprestimo']

X.columns

X.head()

print(f'O formato do X = {X.shape} \n') # verificando o formato do X
print(f'O formato do y = {y.shape}') # verificando o formato do y

# dividindo (split) o conjunto de dados em treinamento e teste
X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size = 0.2, random_state = 42)

"""Utilizando o modelo Random Forest Classifier, o conjunto de dados foi dividido em 80% de treinamento e 20% de teste."""

# instanciando o modelo
model = RandomForestClassifier()

# ajustando (fit) o modelo
clf = model.fit(X_treino, y_treino)

# fazendo previsões no conjunto de teste
y_pred = model.predict(X_teste)

# criando um dataframe para comparar os valores reais e previstos
pd.DataFrame({'Atual': y_teste, 'Previsto': y_pred}).head(10)

"""**Avaliação do modelo**"""

print(f'Accuracy Score: {accuracy_score(y_teste, y_pred) * 100:.2f}%')

print(f"Precision Score: {precision_score(y_teste, y_pred, average='micro'):.2f}")

print(f"F1-Score: {f1_score(y_teste, y_pred, average='micro')}")

# relatório de classificação
print(classification_report(y_teste, y_pred))

"""**Conclusão**

Accuracy Score (acurácia)

Accuracy score (acurácia) é basicamente a porcentagem de previsões realizadas corretamente pelo modelo de todas as previsões (número de previsões corretas dividido pelo número total de previsões).
O valor da accuracy score (acurácia) varia entre 0 e 1 (100%)
A accuracy score (acurácia) do modelo deste projeto é de 86,15%, o que é bom.

Precision Score (precisão)

Precision score (precisão) é resumidamente a porcentagem de previsões positivas corretas feitas pelo modelo, ou seja, o número de previsões positivas corretas dividido pelo número total de previsões positivas.
O valor da precision score (precisão) varia entre 0 e 1.
O cálculo da precision score (precisão) deste modelo usou o parâmetro average = 'micro' que calcula a pontuação de precision score (precisão) globalmente considerando o número total de verdadeiros positivos, falsos positivos e falsos negativos em todas as classes. Tratando todas as instâncias (amostras) igualmente, independentemente de seus class labels (rótulos de classe).
A precision score (precisão) do modelo deste projeto é 0,86 o que indica que o número de falsos positivos é muito menor.

Recall Score

Recall é a porcentagem de previsões negativas corretas feitas pelo modelo, considerando, o número de previsões negativas corretas dividido pelo número total de previsões negativas.
O valor de recall score varia entre 0 e 1.
O recall score deste modelo é 0,86 o que indica que o número de falsos netivos é muito menor.

F1 Score

F1 score é a média harmônica de precision score (precisão e recall score.
É útil quando há classes desbalanceadas no conjunto de dados e fornece melhores resultados ao incluir precision score (precisão) e recall score.

## Deploy

import joblib

**Save the model as a pickle in a file**

joblib.dump(knn, 'filename.pkl')

***Load the model from the file ***

knn_from_joblib = joblib.load('filename.pkl')

**Use the loaded model to make predictions**

knn_from_joblib.predict(X_test)i
"""

joblib.dump(clf, 'modelo_v5.pkl')

clf_from_joblib = joblib.load('modelo_v5.pkl')

clf_from_joblib.predict(X_teste)

